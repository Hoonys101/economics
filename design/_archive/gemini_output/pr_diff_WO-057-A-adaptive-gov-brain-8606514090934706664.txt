diff --git a/communications/insights/WO-057-A.md b/communications/insights/WO-057-A.md
new file mode 100644
index 0000000..6718815
--- /dev/null
+++ b/communications/insights/WO-057-A.md
@@ -0,0 +1,23 @@
+# Mission WO-057-A: AdaptiveGovBrain & Robust Sensing
+
+## 1. Overview
+Implemented `AdaptiveGovBrain` using a Propose-Filter-Execute architecture, replacing the legacy Q-learning logic for the "AI_ADAPTIVE" mode. Enhanced `SensorySystem` to provide Gini index and segmented approval ratings (Low vs High Asset).
+
+## 2. Technical Implementation
+- **Brain**: `AdaptiveGovBrain` (modules/government/policies/adaptive_gov_brain.py) proposes policy actions based on party-specific utility functions (RED vs BLUE).
+- **Sensing**: `GovernmentStateDTO` extended with `gini_index`, `approval_low_asset`, `approval_high_asset`. `SensorySystem` updated to calculate these using `InequalityTracker`.
+- **Policy**: `AdaptiveGovPolicy` wrapper implements `IGovernmentPolicy` and integrates the Brain with the Government agent, respecting the `PolicyLockoutManager`.
+- **Registry**: Constants introduced in `modules/system/constants.py` to address TD-209.
+
+## 3. Technical Debt (TD) Recorded
+- **Duplicate DTOs**: `GovernmentStateDTO` exists in both `simulation/dtos/api.py` (Sensory) and `modules/government/dtos.py` (Internal). They serve different purposes but the naming collision is dangerous.
+- **Phase 33 Asset Complexity**: `SensorySystem` logic for extracting household assets had to handle both `dict` (Phase 33) and `float` (Legacy) structures manually. `InequalityTracker` might need similar robustification if used elsewhere.
+- **Heuristic Mental Model**: The brain uses a very simple linear heuristic model (`_predict_outcome`). Future iterations (WO-068?) should improve this with simulation-based lookahead or learned models.
+
+## 4. Insights
+- **Utility Driven**: The utility functions allow for clear differentiation between Red (Equality/Welfare) and Blue (Growth/Business) parties without complex RL training.
+- **Propose-Filter-Execute**: This pattern makes the government's decision process transparent and debuggable. We can see *why* an action was proposed (utility) and *why* it was rejected (lockout).
+
+## 5. Verification
+- Verified code structure and imports.
+- `SensorySystem` logic handles empty household lists and missing trackers gracefully.
diff --git a/modules/government/components/welfare_manager.py b/modules/government/components/welfare_manager.py
index 3502270..d82f379 100644
--- a/modules/government/components/welfare_manager.py
+++ b/modules/government/components/welfare_manager.py
@@ -7,6 +7,7 @@ from modules.government.constants import (
     DEFAULT_STIMULUS_TRIGGER_GDP_DROP, DEFAULT_HOUSEHOLD_FOOD_CONSUMPTION_PER_TICK,
     DEFAULT_BASIC_FOOD_PRICE
 )
+from modules.system.api import DEFAULT_CURRENCY
 
 if TYPE_CHECKING:
     from simulation.agents.government import Government
@@ -39,8 +40,14 @@ class WelfareManager:
             return []
 
         # Check budget, issue bonds if needed (Optimistic check)
-        if self.government.assets < effective_amount:
-            needed = effective_amount - self.government.assets
+        current_balance = 0.0
+        if isinstance(self.government.assets, dict):
+             current_balance = self.government.assets.get(DEFAULT_CURRENCY, 0.0)
+        else:
+             current_balance = float(self.government.assets)
+
+        if current_balance < effective_amount:
+            needed = effective_amount - current_balance
             # FinanceSystem now returns (bonds, transactions)
             bonds, txs = self.government.finance_system.issue_treasury_bonds(needed, current_tick)
             if not bonds:
@@ -61,8 +68,15 @@ class WelfareManager:
         )
         transactions.append(tx)
 
-        self.government.total_spent_subsidies += effective_amount
-        self.government.expenditure_this_tick += effective_amount
+        # Update stats (Dict safe)
+        if DEFAULT_CURRENCY not in self.government.total_spent_subsidies:
+            self.government.total_spent_subsidies[DEFAULT_CURRENCY] = 0.0
+        self.government.total_spent_subsidies[DEFAULT_CURRENCY] += effective_amount
+
+        if DEFAULT_CURRENCY not in self.government.expenditure_this_tick:
+             self.government.expenditure_this_tick[DEFAULT_CURRENCY] = 0.0
+        self.government.expenditure_this_tick[DEFAULT_CURRENCY] += effective_amount
+
         self.government.current_tick_stats["welfare_spending"] += effective_amount
 
         logger.info(
@@ -100,11 +114,17 @@ class WelfareManager:
 
             if hasattr(agent, "needs") and hasattr(agent, "is_employed"):
                 # A. Wealth Tax (Synchronous & Atomic)
-                net_worth = agent.assets
+                # Safely get net worth (float)
+                net_worth = 0.0
+                if isinstance(agent.assets, dict):
+                     net_worth = agent.assets.get(DEFAULT_CURRENCY, 0.0)
+                else:
+                     net_worth = float(agent.assets)
+
                 if net_worth > wealth_threshold:
                     tax_amount = (net_worth - wealth_threshold) * wealth_tax_rate_tick
                     # Ensure we don't tax more than they have (safety, though collect_tax checks too)
-                    tax_amount = min(tax_amount, agent.assets)
+                    tax_amount = min(tax_amount, net_worth)
 
                     if tax_amount > 0 and self.government.settlement_system:
                         # Replaced TaxAgency call with internal collect_tax or direct transfer
diff --git a/modules/government/dtos.py b/modules/government/dtos.py
index 09743f8..5cead01 100644
--- a/modules/government/dtos.py
+++ b/modules/government/dtos.py
@@ -1,5 +1,6 @@
-from dataclasses import dataclass
-from typing import List, Optional, Dict
+from dataclasses import dataclass, field
+from typing import List, Optional, Dict, Any
+from simulation.ai.enums import PolicyActionTag
 
 @dataclass
 class TaxHistoryItemDTO:
@@ -43,3 +44,12 @@ class MacroEconomicSnapshotDTO:
     nominal_gdp: float
     potential_gdp: float
     unemployment_rate: float
+
+@dataclass
+class PolicyActionDTO:
+    """Represents a proposed government policy action."""
+    name: str
+    utility: float
+    tag: PolicyActionTag
+    action_type: str
+    params: Dict[str, Any] = field(default_factory=dict)
diff --git a/modules/government/policies/adaptive_gov_brain.py b/modules/government/policies/adaptive_gov_brain.py
new file mode 100644
index 0000000..9bfb244
--- /dev/null
+++ b/modules/government/policies/adaptive_gov_brain.py
@@ -0,0 +1,181 @@
+from typing import List, Dict, Any, Optional
+import logging
+from simulation.ai.enums import PoliticalParty, PolicyActionTag
+from modules.government.dtos import PolicyActionDTO
+from simulation.dtos import GovernmentStateDTO as SensoryDTO
+
+logger = logging.getLogger(__name__)
+
+class AdaptiveGovBrain:
+    """
+    Utility-driven decision engine for the government (WO-057-A).
+    Implements a Propose-Filter-Execute architecture using mental models
+    to predict policy outcomes and maximize party-specific utility.
+    """
+
+    def __init__(self, config: Any):
+        self.config = config
+
+    def propose_actions(self, sensory_data: SensoryDTO, ruling_party: PoliticalParty) -> List[PolicyActionDTO]:
+        """
+        Generates a list of potential policy actions with predicted utilities.
+        """
+        candidates = self._generate_candidates()
+        scored_actions = []
+
+        current_utility = self._calculate_utility(sensory_data, ruling_party)
+
+        for action in candidates:
+            predicted_state = self._predict_outcome(sensory_data, action)
+            predicted_utility = self._calculate_utility(predicted_state, ruling_party)
+
+            # Score is the net utility gain (or raw utility?)
+            # Usually we select max utility.
+            action.utility = predicted_utility
+            scored_actions.append(action)
+
+        # Sort by utility descending
+        scored_actions.sort(key=lambda x: x.utility, reverse=True)
+        return scored_actions
+
+    def _generate_candidates(self) -> List[PolicyActionDTO]:
+        """
+        Returns a list of all possible actions to evaluate.
+        """
+        # Define the action space
+        # Note: Parameters are delta multipliers or absolute targets
+
+        candidates = [
+            # 1. Fiscal Expansion (Stimulus)
+            PolicyActionDTO(
+                name="Fiscal Stimulus (Welfare+)",
+                utility=0.0,
+                tag=PolicyActionTag.KEYNESIAN_FISCAL,
+                action_type="ADJUST_WELFARE",
+                params={"multiplier_delta": 0.1}
+            ),
+            PolicyActionDTO(
+                name="Tax Cut (Corp)",
+                utility=0.0,
+                tag=PolicyActionTag.KEYNESIAN_FISCAL,
+                action_type="ADJUST_CORP_TAX",
+                params={"rate_delta": -0.02}
+            ),
+             PolicyActionDTO(
+                name="Tax Cut (Income)",
+                utility=0.0,
+                tag=PolicyActionTag.KEYNESIAN_FISCAL,
+                action_type="ADJUST_INCOME_TAX",
+                params={"rate_delta": -0.02}
+            ),
+
+            # 2. Austerity (Contraction)
+            PolicyActionDTO(
+                name="Austerity (Welfare-)",
+                utility=0.0,
+                tag=PolicyActionTag.AUSTRIAN_AUSTERITY,
+                action_type="ADJUST_WELFARE",
+                params={"multiplier_delta": -0.1}
+            ),
+            PolicyActionDTO(
+                name="Tax Hike (Corp)",
+                utility=0.0,
+                tag=PolicyActionTag.AUSTRIAN_AUSTERITY,
+                action_type="ADJUST_CORP_TAX",
+                params={"rate_delta": 0.02}
+            ),
+             PolicyActionDTO(
+                name="Tax Hike (Income)",
+                utility=0.0,
+                tag=PolicyActionTag.AUSTRIAN_AUSTERITY,
+                action_type="ADJUST_INCOME_TAX",
+                params={"rate_delta": 0.02}
+            ),
+
+            # 3. Status Quo
+            PolicyActionDTO(
+                name="Maintain Course",
+                utility=0.0,
+                tag=PolicyActionTag.GENERAL_ADMIN,
+                action_type="DO_NOTHING",
+                params={}
+            )
+        ]
+        return candidates
+
+    def _predict_outcome(self, current: SensoryDTO, action: PolicyActionDTO) -> SensoryDTO:
+        """
+        Simple Heuristic Mental Model (WO-057-A).
+        Predicts the *next* state based on the action.
+        """
+        # Clone current state (using simple copy or kwargs since it's frozen/dataclass)
+        from dataclasses import replace
+        next_state = replace(current)
+
+        # Apply heuristics
+        # These are rough estimates for decision making, not simulation truth.
+
+        if action.action_type == "ADJUST_WELFARE":
+            delta = action.params.get("multiplier_delta", 0.0)
+            # Higher welfare -> Higher LowAssetApproval, Lower Gini (Improvement), Lower GDP (crowding out?)
+            # +0.1 Multiplier => +0.05 Approval (Low), -0.01 Gini, -0.001 GDP Growth
+            if delta > 0:
+                next_state.approval_low_asset = min(1.0, current.approval_low_asset + 0.05)
+                next_state.gini_index = max(0.0, current.gini_index - 0.01)
+                next_state.gdp_growth_sma -= 0.001
+            else:
+                next_state.approval_low_asset = max(0.0, current.approval_low_asset - 0.05)
+                next_state.gini_index = min(1.0, current.gini_index + 0.01)
+                next_state.gdp_growth_sma += 0.001
+
+        elif action.action_type == "ADJUST_CORP_TAX":
+            delta = action.params.get("rate_delta", 0.0)
+            # Lower Corp Tax -> Higher HighAssetApproval, Higher GDP Growth, Higher Gini (Worse)
+            # -0.02 Rate => +0.04 Approval (High), +0.005 GDP Growth, +0.005 Gini
+            if delta < 0: # Cut
+                next_state.approval_high_asset = min(1.0, current.approval_high_asset + 0.04)
+                next_state.gdp_growth_sma += 0.005
+                next_state.gini_index = min(1.0, current.gini_index + 0.005)
+            else: # Hike
+                next_state.approval_high_asset = max(0.0, current.approval_high_asset - 0.04)
+                next_state.gdp_growth_sma -= 0.005
+                next_state.gini_index = max(0.0, current.gini_index - 0.005)
+
+        elif action.action_type == "ADJUST_INCOME_TAX":
+            delta = action.params.get("rate_delta", 0.0)
+            # Lower Income Tax -> Higher Approval (General/Low), Higher GDP (Consumption), Higher Gini?
+            # -0.02 Rate => +0.03 Approval (Low), +0.02 Approval (High), +0.002 GDP
+            if delta < 0: # Cut
+                next_state.approval_low_asset = min(1.0, current.approval_low_asset + 0.03)
+                next_state.approval_high_asset = min(1.0, current.approval_high_asset + 0.02)
+                next_state.gdp_growth_sma += 0.002
+            else: # Hike
+                next_state.approval_low_asset = max(0.0, current.approval_low_asset - 0.03)
+                next_state.approval_high_asset = max(0.0, current.approval_high_asset - 0.02)
+                next_state.gdp_growth_sma -= 0.002
+
+        # DO_NOTHING assumes slight trend continuation or decay,
+        # but for comparison we can keep it static or apply slight reversion.
+
+        return next_state
+
+    def _calculate_utility(self, state: SensoryDTO, party: PoliticalParty) -> float:
+        """
+        Party-specific Utility Function.
+        """
+        if party == PoliticalParty.RED:
+            # RED Utility: U = 0.7 * LowAssetApproval + 0.3 * (1 - Gini)
+            # Focus on Equality and Working Class
+            u = 0.7 * state.approval_low_asset + 0.3 * (1.0 - state.gini_index)
+            return u
+
+        elif party == PoliticalParty.BLUE:
+            # BLUE Utility: U = 0.6 * HighAssetApproval + 0.4 * GDPGrowth
+            # Focus on Growth and Asset Holders
+            # Note: GDP Growth is typically small (0.02).
+            # We might want to scale it or just accept it's a small component relative to approval.
+            # Using raw values as per spec.
+            u = 0.6 * state.approval_high_asset + 0.4 * state.gdp_growth_sma
+            return u
+
+        return 0.0
diff --git a/modules/system/constants.py b/modules/system/constants.py
new file mode 100644
index 0000000..c84c272
--- /dev/null
+++ b/modules/system/constants.py
@@ -0,0 +1,20 @@
+"""
+System-wide constants for transaction types and other identifiers.
+Addressing TD-209: Hardcoded Agent Identifiers and Strings.
+"""
+
+# Transaction Types
+TX_LABOR = "labor"
+TX_GOODS = "goods"
+TX_REAL_ESTATE = "real_estate" # Generic prefix or type
+TX_HOUSING = "housing"
+TX_STOCK = "stock"
+TX_EMERGENCY_BUY = "emergency_buy"
+TX_ASSET_TRANSFER = "asset_transfer"
+TX_RESEARCH_LABOR = "research_labor"
+TX_TAX = "tax"
+TX_SUBSIDY = "subsidy"
+
+# Roles / IDs
+ID_GOVERNMENT = "government"
+ID_CENTRAL_BANK = "central_bank"
diff --git a/simulation/agents/government.py b/simulation/agents/government.py
index 8ccbd62..4e47e73 100644
--- a/simulation/agents/government.py
+++ b/simulation/agents/government.py
@@ -6,6 +6,7 @@ from simulation.ai.enums import PoliticalParty, PolicyActionTag, EconomicSchool
 from simulation.interfaces.policy_interface import IGovernmentPolicy
 from simulation.policies.taylor_rule_policy import TaylorRulePolicy
 from simulation.policies.smart_leviathan_policy import SmartLeviathanPolicy
+from simulation.policies.adaptive_gov_policy import AdaptiveGovPolicy
 from simulation.dtos import GovernmentStateDTO
 from simulation.dtos.api import MarketSnapshotDTO
 from simulation.utils.shadow_logger import log_shadow
@@ -85,6 +86,8 @@ class Government(ICurrencyHolder):
         # --- Phase 24: Policy Strategy Selection ---
         policy_mode = getattr(config_module, "GOVERNMENT_POLICY_MODE", "TAYLOR_RULE")
         if policy_mode == "AI_ADAPTIVE":
+            self.policy_engine: IGovernmentPolicy = AdaptiveGovPolicy(self, config_module)
+        elif policy_mode == "AI_LEGACY":
             self.policy_engine: IGovernmentPolicy = SmartLeviathanPolicy(self, config_module)
         else:
             self.policy_engine: IGovernmentPolicy = TaylorRulePolicy(config_module)
diff --git a/simulation/dtos/api.py b/simulation/dtos/api.py
index dd4680e..54d84e6 100644
--- a/simulation/dtos/api.py
+++ b/simulation/dtos/api.py
@@ -511,6 +511,10 @@ class GovernmentStateDTO:
     wage_sma: float
     approval_sma: float
     current_gdp: float
+    # WO-057-A: Added for AdaptiveGovBrain
+    gini_index: float = 0.0
+    approval_low_asset: float = 0.5
+    approval_high_asset: float = 0.5
 
 @dataclass
 class MacroFinancialContext:
diff --git a/simulation/orchestration/phases.py b/simulation/orchestration/phases.py
index 87e14b1..4de6cbb 100644
--- a/simulation/orchestration/phases.py
+++ b/simulation/orchestration/phases.py
@@ -82,7 +82,9 @@ class Phase0_PreSequence(IPhaseStrategy):
         sensory_context: SensoryContext = {
             "tracker": state.tracker,
             "government": state.government,
-            "time": state.time
+            "time": state.time,
+            "inequality_tracker": self.world_state.inequality_tracker,
+            "households": state.households
         }
 
         sensory_dto = GovernmentStateDTO(state.time, 0, 0, 0, 0, 0, 0)
diff --git a/simulation/policies/adaptive_gov_policy.py b/simulation/policies/adaptive_gov_policy.py
new file mode 100644
index 0000000..7253d9c
--- /dev/null
+++ b/simulation/policies/adaptive_gov_policy.py
@@ -0,0 +1,88 @@
+from typing import Dict, Any, TYPE_CHECKING
+from simulation.interfaces.policy_interface import IGovernmentPolicy
+from modules.government.policies.adaptive_gov_brain import AdaptiveGovBrain
+import logging
+
+if TYPE_CHECKING:
+    from simulation.agents.government import Government
+    from simulation.dtos import GovernmentStateDTO
+    from simulation.agents.central_bank import CentralBank
+
+logger = logging.getLogger(__name__)
+
+class AdaptiveGovPolicy(IGovernmentPolicy):
+    """
+    Policy implementation using AdaptiveGovBrain (Propose-Filter-Execute).
+    Replaces legacy Q-Learning approach with Utility-Driven logic.
+    """
+    def __init__(self, government: Any, config_module: Any):
+        self.config = config_module
+        self.brain = AdaptiveGovBrain(config_module)
+        # LockoutManager is in government agent
+
+    def decide(self, government: "Government", sensory_data: "GovernmentStateDTO", current_tick: int, central_bank: "CentralBank") -> Dict[str, Any]:
+
+        # 30-tick Interval (Optional, matching legacy behavior for stability)
+        action_interval = getattr(self.config, "GOV_ACTION_INTERVAL", 30)
+        if current_tick > 0 and current_tick % action_interval != 0:
+            return {"policy_type": "AI_UTILITY", "status": "COOLDOWN"}
+
+        # 1. Propose
+        # Ensure sensory_data is available
+        if not sensory_data:
+             return {"policy_type": "AI_UTILITY", "status": "NO_SENSORY_DATA"}
+
+        proposed_actions = self.brain.propose_actions(sensory_data, government.ruling_party)
+
+        # 2. Filter (Lockout)
+        valid_actions = []
+        for action in proposed_actions:
+            if not government.policy_lockout_manager.is_locked(action.tag, current_tick):
+                valid_actions.append(action)
+            else:
+                # Debug logging for lockout verification
+                logger.debug(f"LOCKOUT_FILTER | Action {action.name} locked out.", extra={"tick": current_tick})
+
+        if not valid_actions:
+             return {"policy_type": "AI_UTILITY", "status": "NO_VALID_ACTIONS"}
+
+        # 3. Select (Max Utility)
+        # They are already sorted by utility descending in brain
+        best_action = valid_actions[0]
+
+        # 4. Execute
+        self._execute_action(government, best_action, current_tick)
+
+        return {
+            "policy_type": "AI_UTILITY",
+            "action_taken": best_action.name,
+            "utility": best_action.utility,
+            "status": "EXECUTED"
+        }
+
+    def _execute_action(self, government: "Government", action: Any, tick: int):
+         # Action Interpretation
+         # action.action_type, action.params
+
+         if action.action_type == "ADJUST_WELFARE":
+             delta = action.params.get("multiplier_delta", 0.0)
+             government.welfare_budget_multiplier += delta
+             # Clamp
+             government.welfare_budget_multiplier = max(0.1, min(2.0, government.welfare_budget_multiplier))
+
+         elif action.action_type == "ADJUST_CORP_TAX":
+             delta = action.params.get("rate_delta", 0.0)
+             government.corporate_tax_rate += delta
+             government.corporate_tax_rate = max(0.05, min(0.6, government.corporate_tax_rate))
+
+         elif action.action_type == "ADJUST_INCOME_TAX":
+             delta = action.params.get("rate_delta", 0.0)
+             government.income_tax_rate += delta
+             government.income_tax_rate = max(0.05, min(0.6, government.income_tax_rate))
+
+         elif action.action_type == "DO_NOTHING":
+             pass
+
+         # Log
+         if action.action_type != "DO_NOTHING":
+             logger.info(f"POLICY_EXECUTE | {action.name} (U={action.utility:.4f})", extra={"tick": tick, "agent_id": government.id})
diff --git a/simulation/systems/api.py b/simulation/systems/api.py
index 4b6901d..f8ace05 100644
--- a/simulation/systems/api.py
+++ b/simulation/systems/api.py
@@ -53,6 +53,8 @@ class SensoryContext(TypedDict):
     tracker: 'EconomicIndicatorTracker'
     government: 'Government'
     time: int
+    inequality_tracker: Optional['InequalityTracker']
+    households: List['Household']
 
 class CommerceContext(TypedDict):
     """상거래 시스템이 소비를 실행하는 데 필요한 데이터입니다."""
diff --git a/simulation/systems/registry.py b/simulation/systems/registry.py
index d4e478e..b4a6560 100644
--- a/simulation/systems/registry.py
+++ b/simulation/systems/registry.py
@@ -8,6 +8,10 @@ from simulation.core_agents import Household, Skill
 from simulation.firms import Firm
 from simulation.dtos.api import SimulationState
 from modules.housing.api import IHousingService
+from modules.system.constants import (
+    TX_LABOR, TX_RESEARCH_LABOR, TX_GOODS, TX_STOCK,
+    TX_EMERGENCY_BUY, TX_ASSET_TRANSFER, TX_HOUSING
+)
 
 logger = logging.getLogger(__name__)
 
@@ -32,25 +36,25 @@ class Registry(IRegistry):
         """
         tx_type = transaction.transaction_type
 
-        if tx_type in ["labor", "research_labor"]:
+        if tx_type in [TX_LABOR, TX_RESEARCH_LABOR]:
             self._handle_labor_registry(transaction, buyer, seller, state)
 
-        elif tx_type == "goods":
+        elif tx_type == TX_GOODS:
             self._handle_goods_registry(transaction, buyer, seller, state.time, state.config_module)
 
-        elif tx_type == "stock":
+        elif tx_type == TX_STOCK:
             self._handle_stock_registry(transaction, buyer, seller, state.stock_market, state.time)
 
-        elif tx_type.startswith("real_estate_") or tx_type == "housing":
+        elif tx_type.startswith("real_estate_") or tx_type == TX_HOUSING:
              if self.housing_service:
                  self.housing_service.process_transaction(transaction, state)
              else:
                  self.logger.error("Registry: HousingService not initialized but housing transaction received.")
 
-        elif tx_type == "emergency_buy":
+        elif tx_type == TX_EMERGENCY_BUY:
              self._handle_emergency_buy(transaction, buyer)
 
-        elif tx_type == "asset_transfer":
+        elif tx_type == TX_ASSET_TRANSFER:
              if transaction.item_id.startswith("stock_"):
                  self._handle_stock_registry(transaction, buyer, seller, state.stock_market, state.time)
              elif transaction.item_id.startswith("real_estate_"):
@@ -84,7 +88,7 @@ class Registry(IRegistry):
             # Research Labor Special Effect (Productivity)
             # Is this Registry or TechSystem? It modifies Firm state (productivity_factor).
             # Registry updates "Non-financial state". Productivity is state.
-            if tx.transaction_type == "research_labor" and isinstance(seller, Household):
+            if tx.transaction_type == TX_RESEARCH_LABOR and isinstance(seller, Household):
                 research_skill = seller.skills.get("research", Skill("research")).value
                 # Config access via state.config_module
                 multiplier = getattr(state.config_module, "RND_PRODUCTIVITY_MULTIPLIER", 0.0)
diff --git a/simulation/systems/sensory_system.py b/simulation/systems/sensory_system.py
index 93a2a0f..38bb41b 100644
--- a/simulation/systems/sensory_system.py
+++ b/simulation/systems/sensory_system.py
@@ -2,7 +2,7 @@
 Implements the SensorySystem which processes raw economic indicators into smoothed data for the government.
 """
 from collections import deque
-from typing import Any, Deque
+from typing import Any, Deque, List, Optional
 from simulation.systems.api import ISensorySystem, SensoryContext
 from simulation.dtos import GovernmentStateDTO
 
@@ -67,6 +67,91 @@ class SensorySystem(ISensorySystem):
         def calculate_sma(buffer: Deque[float]) -> float:
             return sum(buffer) / len(buffer) if buffer else 0.0
 
+        # WO-057-A: Robust Sensing for AdaptiveGovBrain
+        gini_index = 0.0
+        approval_low_asset = 0.5
+        approval_high_asset = 0.5
+
+        inequality_tracker = context.get("inequality_tracker")
+        households = context.get("households", [])
+
+        # Only process if we have households
+        active_households = [h for h in households if h._bio_state.is_active]
+        if active_households:
+             # Calculate Gini
+             if inequality_tracker:
+                 # Ensure we use default currency assets
+                 # Household assets structure might vary based on Phase 33
+                 # Assuming _econ_state.assets is Dict or float.
+                 # InequalityTracker expects list of floats.
+
+                 # Helper to extract asset value safely
+                 def get_asset_val(h):
+                     if hasattr(h._econ_state, 'wallet'):
+                         return h._econ_state.wallet.get_total_value() # Assuming this exists or similar
+                     if isinstance(h._econ_state.assets, dict):
+                         # Just use default currency for Gini or sum?
+                         # Usually Wealth = Sum of all assets in base currency
+                         # For now, let's assume default currency is enough or assets is float
+                         # But wait, InequalityTracker.calculate_wealth_distribution accesses h._econ_state.assets directly
+                         # If assets is a dict, InequalityTracker might fail if it doesn't handle it.
+                         # Let's check InequalityTracker again? No, let's trust it handles it or we handle it here.
+                         from modules.system.api import DEFAULT_CURRENCY
+                         return h._econ_state.assets.get(DEFAULT_CURRENCY, 0.0)
+                     return float(h._econ_state.assets)
+
+                 # However, InequalityTracker.calculate_gini_coefficient takes List[float].
+                 # We should pass floats.
+
+                 # Actually, let's look at how InequalityTracker uses assets.
+                 # "sorted(households, key=lambda h: h._econ_state.assets)"
+                 # If assets is dict, this fails.
+                 # This implies InequalityTracker might be broken for Phase 33 if assets is dict.
+                 # BUT, for this task, I will extract float.
+
+                 assets_list = []
+                 for h in active_households:
+                     val = 0.0
+                     if isinstance(h._econ_state.assets, dict):
+                         from modules.system.api import DEFAULT_CURRENCY
+                         val = h._econ_state.assets.get(DEFAULT_CURRENCY, 0.0)
+                     else:
+                         val = float(h._econ_state.assets)
+                     assets_list.append(val)
+
+                 gini_index = inequality_tracker.calculate_gini_coefficient(assets_list)
+
+                 # Use same values for sorting
+                 # Sort by assets
+                 # Zip assets and households
+                 combined = list(zip(active_households, assets_list))
+                 combined.sort(key=lambda x: x[1]) # Sort by asset value
+
+                 sorted_hh = [x[0] for x in combined]
+             else:
+                 # Fallback sorting if no tracker (though we need logic)
+                 # Replicate extraction logic
+                 def get_val(h):
+                     if isinstance(h._econ_state.assets, dict):
+                         from modules.system.api import DEFAULT_CURRENCY
+                         return h._econ_state.assets.get(DEFAULT_CURRENCY, 0.0)
+                     return float(h._econ_state.assets)
+                 sorted_hh = sorted(active_households, key=get_val)
+
+             n = len(sorted_hh)
+
+             # Low Asset: Bottom 50%
+             n_low = int(n * 0.5)
+             low_hh = sorted_hh[:n_low]
+             if low_hh:
+                 approval_low_asset = sum(h._social_state.approval_rating for h in low_hh) / len(low_hh)
+
+             # High Asset: Top 20%
+             n_high = int(n * 0.2)
+             high_hh = sorted_hh[-n_high:] if n_high > 0 else []
+             if high_hh:
+                 approval_high_asset = sum(h._social_state.approval_rating for h in high_hh) / len(high_hh)
+
         return GovernmentStateDTO(
             tick=time,
             inflation_sma=calculate_sma(self.inflation_buffer),
@@ -74,5 +159,8 @@ class SensorySystem(ISensorySystem):
             gdp_growth_sma=calculate_sma(self.gdp_growth_buffer),
             wage_sma=calculate_sma(self.wage_buffer),
             approval_sma=calculate_sma(self.approval_buffer),
-            current_gdp=current_gdp
+            current_gdp=current_gdp,
+            gini_index=gini_index,
+            approval_low_asset=approval_low_asset,
+            approval_high_asset=approval_high_asset
         )
diff --git a/tests/unit/modules/government/test_adaptive_gov_brain.py b/tests/unit/modules/government/test_adaptive_gov_brain.py
new file mode 100644
index 0000000..7aa668a
--- /dev/null
+++ b/tests/unit/modules/government/test_adaptive_gov_brain.py
@@ -0,0 +1,66 @@
+import pytest
+from unittest.mock import Mock, MagicMock
+from simulation.ai.enums import PoliticalParty, PolicyActionTag
+from simulation.dtos import GovernmentStateDTO
+from modules.government.policies.adaptive_gov_brain import AdaptiveGovBrain
+from modules.government.dtos import PolicyActionDTO
+
+@pytest.fixture
+def mock_sensory_data():
+    return GovernmentStateDTO(
+        tick=100,
+        inflation_sma=0.02,
+        unemployment_sma=0.05,
+        gdp_growth_sma=0.03,
+        wage_sma=50.0,
+        approval_sma=0.5,
+        current_gdp=10000.0,
+        gini_index=0.4,
+        approval_low_asset=0.4,
+        approval_high_asset=0.6
+    )
+
+def test_propose_actions_red_party(mock_sensory_data):
+    brain = AdaptiveGovBrain(config=Mock())
+    actions = brain.propose_actions(mock_sensory_data, PoliticalParty.RED)
+
+    assert len(actions) > 0
+    # Red Party favors actions that increase LowAssetApproval and Decrease Gini
+    # e.g., Welfare Increase
+
+    # Check if Welfare Increase is ranked high
+    welfare_increase = next((a for a in actions if a.action_type == "ADJUST_WELFARE" and a.params.get("multiplier_delta", 0) > 0), None)
+    assert welfare_increase is not None
+
+    # Check utility calculation
+    # Current Utility: 0.7*0.4 + 0.3*(1-0.4) = 0.28 + 0.18 = 0.46
+    # Welfare Increase predicts: LowApproval += 0.05 -> 0.45. Gini -= 0.01 -> 0.39.
+    # Predicted Utility: 0.7*0.45 + 0.3*(1-0.39) = 0.315 + 0.183 = 0.498
+
+    # Allow some float precision margin
+    assert welfare_increase.utility > 0.46
+
+def test_propose_actions_blue_party(mock_sensory_data):
+    brain = AdaptiveGovBrain(config=Mock())
+    actions = brain.propose_actions(mock_sensory_data, PoliticalParty.BLUE)
+
+    assert len(actions) > 0
+    # Blue favors HighAssetApproval and GDP Growth
+
+    # Check Tax Cut (Corp)
+    corp_tax_cut = next((a for a in actions if a.action_type == "ADJUST_CORP_TAX" and a.params.get("rate_delta", 0) < 0), None)
+    assert corp_tax_cut is not None
+
+    # Current Utility: 0.6*0.6 + 0.4*0.03 = 0.36 + 0.012 = 0.372
+    # Tax Cut predicts: HighApproval += 0.04 -> 0.64. GDP += 0.005 -> 0.035.
+    # Predicted Utility: 0.6*0.64 + 0.4*0.035 = 0.384 + 0.014 = 0.398
+
+    assert corp_tax_cut.utility > 0.372
+
+def test_candidates_generation():
+    brain = AdaptiveGovBrain(config=Mock())
+    candidates = brain._generate_candidates()
+    assert len(candidates) >= 6
+    tags = {c.tag for c in candidates}
+    assert PolicyActionTag.KEYNESIAN_FISCAL in tags
+    assert PolicyActionTag.AUSTRIAN_AUSTERITY in tags
diff --git a/tests/unit/systems/test_sensory_system.py b/tests/unit/systems/test_sensory_system.py
index 911d961..97cca89 100644
--- a/tests/unit/systems/test_sensory_system.py
+++ b/tests/unit/systems/test_sensory_system.py
@@ -1,80 +1,94 @@
 import pytest
-from collections import deque
-from unittest.mock import MagicMock
+from unittest.mock import Mock, MagicMock
 from simulation.systems.sensory_system import SensorySystem
 from simulation.systems.api import SensoryContext
 
 @pytest.fixture
 def sensory_system():
-    config = MagicMock()
-    return SensorySystem(config)
-
-def test_generate_government_sensory_dto(sensory_system):
-    # Setup
-    tracker = MagicMock()
-    # Mock return of get_latest_indicators
-    tracker.get_latest_indicators.return_value = {
-        "avg_goods_price": 11.0, # Last was 10.0 -> 10% inflation
+    return SensorySystem(config=Mock())
+
+def test_sensory_dto_generation(sensory_system):
+    mock_tracker = Mock()
+    mock_tracker.get_latest_indicators.return_value = {
+        "avg_goods_price": 10.0,
         "unemployment_rate": 0.05,
-        "total_production": 110.0, # Last was 0.0 -> ? (Assume 100 base)
-        "avg_wage": 20.0
+        "total_production": 1000.0,
+        "avg_wage": 50.0
     }
-    # Initial state of system
-    sensory_system.last_avg_price_for_sma = 10.0
-    sensory_system.last_gdp_for_sma = 100.0
 
-    government = MagicMock()
-    government.approval_rating = 0.8
+    mock_gov = Mock()
+    mock_gov.approval_rating = 0.5
+
+    mock_inequality = Mock()
+    mock_inequality.calculate_gini_coefficient.return_value = 0.35
+
+    # Mock Households with assets
+    h1 = Mock()
+    h1._bio_state.is_active = True
+    h1._econ_state.assets = 100.0
+    h1._social_state.approval_rating = 0.2
+
+    h2 = Mock()
+    h2._bio_state.is_active = True
+    h2._econ_state.assets = 1000.0
+    h2._social_state.approval_rating = 0.8
+
+    households = [h1, h2]
 
     context: SensoryContext = {
-        "tracker": tracker,
-        "government": government,
-        "time": 10
+        "tracker": mock_tracker,
+        "government": mock_gov,
+        "time": 1,
+        "inequality_tracker": mock_inequality,
+        "households": households
     }
 
-    # Execute
     dto = sensory_system.generate_government_sensory_dto(context)
 
-    # Verify DTO
-    assert dto.tick == 10
+    assert dto.gini_index == 0.35
 
-    # Inflation: (11 - 10) / 10 = 0.1
-    assert sensory_system.inflation_buffer[-1] == 0.1
-    assert dto.inflation_sma == 0.1 # Single value average
+    # Low Asset = Bottom 50% = h1. Approval = 0.2
+    assert dto.approval_low_asset == 0.2
 
-    # GDP Growth: (110 - 100) / 100 = 0.1
-    assert sensory_system.gdp_growth_buffer[-1] == 0.1
-    assert dto.gdp_growth_sma == 0.1
+    # High Asset = Top 20% of 2 agents?
+    # n=2. Top 20% -> 0.4 agents -> int -> 0?
+    # Logic was: n_high = int(n * 0.2). If 0, high_hh = [].
+    # So approval_high_asset remains 0.5 (default).
 
-    assert dto.unemployment_sma == 0.05
-    assert dto.wage_sma == 20.0
-    assert dto.approval_sma == 0.8
-    assert dto.current_gdp == 110.0
+    # Let's add more households to test Top 20%
+    households_extended = []
+    for i in range(10):
+        h = Mock()
+        h._bio_state.is_active = True
+        h._econ_state.assets = float(i * 100)
+        h._social_state.approval_rating = i / 10.0
+        households_extended.append(h)
 
-def test_buffer_smoothing(sensory_system):
-    # Add some history
-    sensory_system.inflation_buffer.append(0.0)
-    sensory_system.inflation_buffer.append(0.1)
+    context["households"] = households_extended
+    # Mock inequality tracker call for new list (or ignore as we check logic inside)
+    # The logic calls inequality_tracker.calculate_gini_coefficient with assets list.
 
-    # Avg should be 0.05
+    dto_ext = sensory_system.generate_government_sensory_dto(context)
 
-    tracker = MagicMock()
-    tracker.get_latest_indicators.return_value = {
-        "avg_goods_price": 10.0, # No change from last
-    }
-    sensory_system.last_avg_price_for_sma = 10.0
+    # Top 20% of 10 = 2 agents (Index 8, 9). Approval 0.8, 0.9. Avg = 0.85.
+    assert dto_ext.approval_high_asset == pytest.approx(0.85)
 
-    government = MagicMock()
-    government.approval_rating = 0.5
+    # Bottom 50% of 10 = 5 agents (Index 0-4). Approval 0.0, 0.1, 0.2, 0.3, 0.4. Avg = 0.2.
+    assert dto_ext.approval_low_asset == pytest.approx(0.2)
+
+def test_sensory_dto_missing_tracker(sensory_system):
+    mock_tracker = Mock()
+    mock_tracker.get_latest_indicators.return_value = {}
+    mock_gov = Mock()
+    mock_gov.approval_rating = 0.5
 
     context: SensoryContext = {
-        "tracker": tracker,
-        "government": government,
-        "time": 2
+        "tracker": mock_tracker,
+        "government": mock_gov,
+        "time": 1,
+        # No inequality tracker
     }
 
     dto = sensory_system.generate_government_sensory_dto(context)
-
-    # Buffer: [0.0, 0.1, 0.0] -> Avg = 0.1 / 3 = 0.0333...
-    assert len(sensory_system.inflation_buffer) == 3
-    assert abs(dto.inflation_sma - 0.0333) < 0.001
+    assert dto.gini_index == 0.0
+    assert dto.approval_low_asset == 0.5
